{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spacypipeline](https://spacy.io/pipeline-fde48da9b43661abcdf62ab70a546d71.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spacy.io/usage/processing-pipelines\n",
    "\n",
    "When you call nlp on a text, spaCy first tokenizes the text to produce a Doc object. The Doc is then processed in several different steps – this is also referred to as the **processing pipeline**. The pipeline used by the default models consists of a tagger, a parser and an entity recognizer. Each pipeline component returns the processed Doc, which is then passed on to the next component.\n",
    "\n",
    "**How pipelines work**\n",
    "\n",
    "spaCy makes it very easy to create your own pipelines consisting of reusable components – this includes spaCy’s default tagger, parser and entity recognizer, but also your own custom processing functions. A pipeline component can be added to an already existing nlp object, specified when initializing a Language class, or defined within a model package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Get Started\n",
    "\n",
    "* install and import spacy\n",
    "* install and load language model.\n",
    "\n",
    "Another great feature of spacy are the pre-built trained pipelines\n",
    "See here: https://spacy.io/usage/models#download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy # pip install spacy #takes a minute or two.\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') #python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Netanyahu's visit was cut short by reports late Sunday that a rocket was fired from Gaza into central Israel, wounding at least seven people. Following criticism from political opponents over what they consider the prime minister's unclear stance toward the militant political group, Israel responded with a series of strikes into Gaza against Hamas, which largely governs the contested strip. President Donald Trump tacitly endorsed the strike following his meetings with Netanyahu, calling the Hamas attack \\\"despicable.\\\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Netanyahu\\'s visit was cut short by reports late Sunday that a rocket was fired from Gaza into central Israel, wounding at least seven people. Following criticism from political opponents over what they consider the prime minister\\'s unclear stance toward the militant political group, Israel responded with a series of strikes into Gaza against Hamas, which largely governs the contested strip. President Donald Trump tacitly endorsed the strike following his meetings with Netanyahu, calling the Hamas attack \"despicable.\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Netanyahu's visit was cut short by reports late Sunday that a rocket was fired from Gaza into central Israel, wounding at least seven people. Following criticism from political opponents over what they consider the prime minister's unclear stance toward the militant political group, Israel responded with a series of strikes into Gaza against Hamas, which largely governs the contested strip. President Donald Trump tacitly endorsed the strike following his meetings with Netanyahu, calling the Hamas attack \"despicable.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netanyahu\n",
      "'s\n",
      "visit\n",
      "was\n",
      "cut\n",
      "short\n",
      "by\n",
      "reports\n",
      "late\n",
      "Sunday\n",
      "that\n",
      "a\n",
      "rocket\n",
      "was\n",
      "fired\n",
      "from\n",
      "Gaza\n",
      "into\n",
      "central\n",
      "Israel\n",
      ",\n",
      "wounding\n",
      "at\n",
      "least\n",
      "seven\n",
      "people\n",
      ".\n",
      "Following\n",
      "criticism\n",
      "from\n",
      "political\n",
      "opponents\n",
      "over\n",
      "what\n",
      "they\n",
      "consider\n",
      "the\n",
      "prime\n",
      "minister\n",
      "'s\n",
      "unclear\n",
      "stance\n",
      "toward\n",
      "the\n",
      "militant\n",
      "political\n",
      "group\n",
      ",\n",
      "Israel\n",
      "responded\n",
      "with\n",
      "a\n",
      "series\n",
      "of\n",
      "strikes\n",
      "into\n",
      "Gaza\n",
      "against\n",
      "Hamas\n",
      ",\n",
      "which\n",
      "largely\n",
      "governs\n",
      "the\n",
      "contested\n",
      "strip\n",
      ".\n",
      "President\n",
      "Donald\n",
      "Trump\n",
      "tacitly\n",
      "endorsed\n",
      "the\n",
      "strike\n",
      "following\n",
      "his\n",
      "meetings\n",
      "with\n",
      "Netanyahu\n",
      ",\n",
      "calling\n",
      "the\n",
      "Hamas\n",
      "attack\n",
      "\"\n",
      "despicable\n",
      ".\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['back', 'other', 'toward', 'go', 'wherein', \"'ll\", 'move', 'anyhow', 'regarding', 'can', 'seeming', 'everywhere', 'whither', 'around', 'four', 'may', 'him', 'his', \"'re\", 'something', 'not', 'whereafter', 'those', 'them', 'does', 'twenty', '‘ll', 'also', 'none', \"n't\", 'becoming', 'without', 'rather', 'my', 'behind', '’s', 'however', 'empty', 'ca', 'show', 'whole', 'whence', 'many', 'wherever', 'another', 'sometimes', 'to', 'had', 'mostly', 'whoever', 'throughout', 'else', 'among', '’ll', 'any', 'here', 'on', 'now', 'thereupon', 'amount', 'upon', 'quite', \"'d\", 'latterly', 'amongst', 'then', 'within', 'below', 'through', 'whose', 'serious', '’d', 'hundred', 'n’t', 'against', 'seemed', 'keep', 'most', 'name', 'beforehand', 'namely', 'along', 'never', '’m', 'yourselves', 'himself', 'nobody', 'have', 'nowhere', 'ours', 'first', 'herein', 'onto', 'such', 'because', 'how', 'anything', 'since', 'yourself', 'top', 'seems', 'down', 'its', 'over', 'one', 'few', 'nothing', 'thereby', 'herself', 'who', 'too', 'must', 'alone', 'sixty', 'therein', 'side', 'from', 'you', 'somehow', 'during', 'towards', 'two', 'eleven', 'being', 'full', 'thereafter', 'whereas', 'thence', 'me', 'give', 'unless', 'about', 'bottom', 'even', 'last', 'take', 'hereafter', 'five', 'her', 'elsewhere', 'if', 'it', 'that', 'again', 'although', 'there', 're', 'we', 'yet', 'put', 'nevertheless', 'no', 'latter', '’re', 'did', 'as', 'above', 'someone', 'across', '‘ve', 'via', 'various', 'both', 'anywhere', 'into', 'an', 'become', 'off', 'myself', 'enough', 'almost', 'every', 'n‘t', 'so', '‘m', 'either', 'cannot', 'she', 'why', 'i', 'been', 'will', 'at', 'indeed', 'seem', 'these', 'used', 'thru', 'beside', 'might', 'whereupon', 'where', 'mine', 'six', 'done', 'a', 'part', '‘re', 'fifteen', 'least', 'your', 'perhaps', 'several', 'whom', 'anyway', 'formerly', 'three', 'ever', 'otherwise', 'twelve', 'their', 'further', 'sometime', 'thus', 'together', 'ourselves', 'just', 'yours', 'hers', 'next', 'became', 'more', 'which', 'very', 'before', 'see', \"'s\", '’ve', 'out', 'former', 'often', 'becomes', 'while', 'call', 'until', 'all', 'doing', 'once', 'in', 'of', 'eight', 'per', 'this', 'when', 'make', 'less', 'say', 'besides', 'has', 'fifty', 'front', 'neither', 'though', 'would', 'made', 'meanwhile', 'between', 'third', 'whenever', 'hereby', 'beyond', 'therefore', 'everyone', 'everything', 'only', 'themselves', 'noone', 'afterwards', 'get', 'should', 'itself', 'still', 'already', 'and', 'well', 'ten', 'using', 'than', \"'m\", 'except', 'hereupon', 'nor', 'they', 'are', '‘d', 'really', 'was', 'some', 'please', 'or', 'with', 'moreover', 'somewhere', 'after', 'forty', 'always', 'nine', 'hence', 'up', 'what', '‘s', 'the', 'us', 'each', 'whether', 'were', 'much', 'same', 'am', 'could', 'our', 'is', 'anyone', 'whereby', 'due', 'whatever', 'by', 'for', 'do', 'but', 'he', \"'ve\", 'own', 'under', 'others', 'be']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens that are not stopwords in my text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netanyahu\n",
      "visit\n",
      "cut\n",
      "short\n",
      "reports\n",
      "late\n",
      "Sunday\n",
      "rocket\n",
      "fired\n",
      "Gaza\n",
      "central\n",
      "Israel\n",
      ",\n",
      "wounding\n",
      "seven\n",
      "people\n",
      ".\n",
      "Following\n",
      "criticism\n",
      "political\n",
      "opponents\n",
      "consider\n",
      "prime\n",
      "minister\n",
      "unclear\n",
      "stance\n",
      "militant\n",
      "political\n",
      "group\n",
      ",\n",
      "Israel\n",
      "responded\n",
      "series\n",
      "strikes\n",
      "Gaza\n",
      "Hamas\n",
      ",\n",
      "largely\n",
      "governs\n",
      "contested\n",
      "strip\n",
      ".\n",
      "President\n",
      "Donald\n",
      "Trump\n",
      "tacitly\n",
      "endorsed\n",
      "strike\n",
      "following\n",
      "meetings\n",
      "Netanyahu\n",
      ",\n",
      "calling\n",
      "Hamas\n",
      "attack\n",
      "\"\n",
      "despicable\n",
      ".\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.is_stop == False:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the stop words in my text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s\n",
      "was\n",
      "by\n",
      "that\n",
      "a\n",
      "was\n",
      "from\n",
      "into\n",
      "at\n",
      "least\n",
      "from\n",
      "over\n",
      "what\n",
      "they\n",
      "the\n",
      "'s\n",
      "toward\n",
      "the\n",
      "with\n",
      "a\n",
      "of\n",
      "into\n",
      "against\n",
      "which\n",
      "the\n",
      "the\n",
      "his\n",
      "with\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netanyahu Netanyahu\n",
      "'s 's\n",
      "visit visit\n",
      "was be\n",
      "cut cut\n",
      "short short\n",
      "by by\n",
      "reports report\n",
      "late late\n",
      "Sunday Sunday\n",
      "that that\n",
      "a a\n",
      "rocket rocket\n",
      "was be\n",
      "fired fire\n",
      "from from\n",
      "Gaza Gaza\n",
      "into into\n",
      "central central\n",
      "Israel Israel\n",
      ", ,\n",
      "wounding wound\n",
      "at at\n",
      "least least\n",
      "seven seven\n",
      "people people\n",
      ". .\n",
      "Following follow\n",
      "criticism criticism\n",
      "from from\n",
      "political political\n",
      "opponents opponent\n",
      "over over\n",
      "what what\n",
      "they they\n",
      "consider consider\n",
      "the the\n",
      "prime prime\n",
      "minister minister\n",
      "'s 's\n",
      "unclear unclear\n",
      "stance stance\n",
      "toward toward\n",
      "the the\n",
      "militant militant\n",
      "political political\n",
      "group group\n",
      ", ,\n",
      "Israel Israel\n",
      "responded respond\n",
      "with with\n",
      "a a\n",
      "series series\n",
      "of of\n",
      "strikes strike\n",
      "into into\n",
      "Gaza Gaza\n",
      "against against\n",
      "Hamas Hamas\n",
      ", ,\n",
      "which which\n",
      "largely largely\n",
      "governs govern\n",
      "the the\n",
      "contested contest\n",
      "strip strip\n",
      ". .\n",
      "President President\n",
      "Donald Donald\n",
      "Trump Trump\n",
      "tacitly tacitly\n",
      "endorsed endorse\n",
      "the the\n",
      "strike strike\n",
      "following follow\n",
      "his his\n",
      "meetings meeting\n",
      "with with\n",
      "Netanyahu Netanyahu\n",
      ", ,\n",
      "calling call\n",
      "the the\n",
      "Hamas Hamas\n",
      "attack attack\n",
      "\" \"\n",
      "despicable despicable\n",
      ". .\n",
      "\" \"\n"
     ]
    }
   ],
   "source": [
    "for lem in doc:\n",
    "    print(lem.text, lem.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try with another text, this time a bit shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('run runs running runner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run run\n",
      "runs run\n",
      "running run\n",
      "runner runner\n"
     ]
    }
   ],
   "source": [
    "for lem in doc:\n",
    "    print(lem.text, lem.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('President tacitly endorsed the strike following his meetings with Netanyahu.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President PROPN\n",
      "tacitly ADV\n",
      "endorsed VERB\n",
      "the DET\n",
      "strike NOUN\n",
      "following VERB\n",
      "his PRON\n",
      "meetings NOUN\n",
      "with ADP\n",
      "Netanyahu PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span class=\"mark\">TODO</span>**: For this same text, now also print the lemmas along with pos and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President PROPN President\n",
      "tacitly ADV tacitly\n",
      "endorsed VERB endorse\n",
      "the DET the\n",
      "strike NOUN strike\n",
      "following VERB follow\n",
      "his PRON his\n",
      "meetings NOUN meeting\n",
      "with ADP with\n",
      "Netanyahu PROPN Netanyahu\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "# Your code below\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"New York City on Tuesday declared a public health emergency and ordered mandatory measles vaccinations amid an outbreak, becoming the latest national flash point over refusals to inoculate against dangerous diseases. At least 285 people have contracted measles in the city since September, mostly in Brooklyn’s Williamsburg neighborhood. The order covers four Zip codes there, Mayor Bill de Blasio (D) said Tuesday. The mandate orders all unvaccinated people in the area, including a concentration of Orthodox Jews, to receive inoculations, including for children as young as 6 months old. Anyone who resists could be fined up to $1,000.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City 0 13 GPE\n",
      "Tuesday 17 24 DATE\n",
      "At least 285 217 229 CARDINAL\n",
      "September 279 288 DATE\n",
      "Brooklyn 300 308 GPE\n",
      "four 355 359 CARDINAL\n",
      "Zip 360 363 PERSON\n",
      "Bill de Blasio 383 397 PERSON\n",
      "Tuesday 407 414 DATE\n",
      "Orthodox 501 509 NORP\n",
      "6 months old 576 588 DATE\n",
      "up to $1,000 624 636 MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York City\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tuesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " declared a public health emergency and ordered mandatory measles vaccinations amid an outbreak, becoming the latest national flash point over refusals to inoculate against dangerous diseases. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    At least 285\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " people have contracted measles in the city since \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    September\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", mostly in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brooklyn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "’s Williamsburg neighborhood. The order covers \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    four\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zip\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " codes there, Mayor \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bill de Blasio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " (D) said \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tuesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". The mandate orders all unvaccinated people in the area, including a concentration of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Orthodox\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " Jews, to receive inoculations, including for children as young as \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    6 months old\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". Anyone who resists could be fined \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    up to $1,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style = 'ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span class=\"mark\">TODO</span>**: Print all the named entities for the following text:\n",
    "\n",
    "\"WHO recommends use of AstraZeneca Covid-19 vaccine as two-dose shot, 8 to 12 weeks apart\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over 92% 25 33 PERCENT\n",
      "CDC 85 88 ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Double masking can block over 92% of potentially infectious particles from escaping, CDC study says\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN, LABEL, start, end\n",
      "-----------------------------\n",
      "AstraZeneca PRODUCT 22 33\n",
      "two CARDINAL 54 57\n",
      "8 to 12 weeks DATE 69 82\n"
     ]
    }
   ],
   "source": [
    "text = \"WHO recommends use of AstraZeneca Covid-19 vaccine as two-dose shot, 8 to 12 weeks apart\"\n",
    "\n",
    "doc = nlp(text)\n",
    "print('TOKEN, LABEL, start, end\\n-----------------------------')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_, ent.start_char, ent.end_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spacy tags for POS and NER**\n",
    "\n",
    "https://spacy.io/api/annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
